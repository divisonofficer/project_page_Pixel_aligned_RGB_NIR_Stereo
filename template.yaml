theme: default # default || classic || dark
organization: POSTECH Computational Imaging Group
twitter: #'@'
title: Pixel-aligned RGB-NIR Stereo Imaging and Dataset\nfor Robot Vision
journal: "CVPR'25"
resources:
  paper: # https://openreview.net/
  arxiv: https://arxiv.org/abs/2411.18025
  code: https://github.com/divisonofficer/cvpr5308
  video: https://www.youtube.com/watch?v=KPmXeSYVFBE
  demo: #https://colab.research.google.com/
  huggingface: https://huggingface.co/datasets/DivisonOfficer/Pixel-aligned_RGB-NIR_stereo_dataset
description: academic projectpage template that supports markdown and KaTeX

image: #https://denkiwakame.github.io/academic-project-template/teaser.jpg
url: https://denkiwakame.github.io/academic-project-template
speakerdeck: # speakerdeck slide ID
authors:
  - name: Jinnyeong Kim
    affiliation: [1]
    url: https://divisonofficer.github.io/
    position: Graudate Student
  - name: Seung-Hwan Baek
    affiliation: [1]
    position: Professor
    url: https://www.shbaek.com/
affiliations:
  - POSTECH
meta:
bibtex: >
  @article{doe2024superai,
    author    = {Jinnyeong Kim, Seung-Hwan Baek},
    title     = {Pixel-aligned RGB-NIR Stereo Imaging and Dataset for Robot Vision},
    conference   = {The IEEE/CVF Conference on Computer Vision and Pattern Recognition 2025},
    year      = {2025},
    keywords  = {Machine Vision, Robot Vision, Vision Dataset},
    doi       = {10.48550/arXiv.2411.18025},
    url       = {https://arxiv.org/abs/2411.18025},
  }

teaser: |
  <div uk-slider>
    <div class="uk-slider-items uk-child-width-1-1 uk-child-width-1-3@m uk-grid">
      <div>
        <video
          src="driving_indoor__.mp4"
          loop
          muted
          uk-video="autoplay:inview"
          />
      </div>
      <div>
        <video
          src="driving_dark__.mp4"
          loop
          muted
          uk-video="autoplay:inview"
          />
      </div>
      <div>
        <video
          src="driving_day_outdoor__.mp4"
          loop
          muted
          uk-video="autoplay:inview"
          />
      </div>
      <div>
        <video
          src="driving_dark__2.mp4"
          loop
          muted
          uk-video="autoplay:inview"
          />
      </div>
    </div>
    <div class="uk-flex uk-flex-center uk-margin-small">
      <a class="uk-icon-button" href uk-slidenav-previous uk-slider-item="previous"></a>
      <a class="uk-icon-button uk-margin-small-left" href uk-slidenav-next uk-slider-item="next"></a>
    </div>
  </div>
abstract: |
  Integrating RGB and NIR imaging provides complementary spectral information, enhancing robotic vision in challenging lighting conditions. However, existing datasets and imaging systems lack pixel-level alignment between RGB and NIR images, posing challenges for downstream tasks. In this paper, we develop a robotic vision system equipped with two pixel-aligned RGB-NIR stereo cameras and a LiDAR sensor mounted on a mobile robot. The system simultaneously captures RGB stereo images, NIR stereo images, and temporally synchronized LiDAR point cloud. Utilizing the mobility of the robot, we present a dataset containing continuous video frames with pixel-aligned RGB and NIR stereo pairs under diverse lighting conditions. We introduce two methods that utilize our pixel-aligned RGB-NIR images: an RGB-NIR image fusion method and a feature fusion method. The first approach enables existing RGB-pretrained vision models to directly utilize RGB-NIR information without fine-tuning. The second approach fine-tunes existing vision models to more effectively utilize RGB-NIR information. Experimental results demonstrate the effectiveness of using pixel-aligned RGB-NIR images across diverse lighting conditions.

body:
  - title: Imaging System with a Mobile Robot
    text: |
      <div class="uk-margin uk-padding">
        <p>Our robotic vision system integrates two pixel-aligned RGB-NIR stereo cameras and a LiDAR sensor, 
        all mounted on a mobile robotic platform. The system captures RGB stereo images,
         NIR stereo images, and temporally synchronized LiDAR point clouds, 
         ensuring comprehensive spatial and spectral data acquisition. 
         To enhance the quality and robustness of NIR image capture, 
         we have implemented an NIR LED bar light source, providing consistent illumination across varying environments.</p>
      </div>
      <div class="uk-position-relative" uk-slideshow="animation: fade">
        <div class="uk-slideshow-items" uk-margin-large >
          <div > 
            <img src="fig_imaging_1.png" alt="" uk-cover  style="margin-top: 2rem;">
          </div>
          <div >
            <img src="fig_imaging_2.png" alt="" uk-cover style="margin-top: 2rem;">
          </div>
          <div >
            <img src="fig_imaging_3.png" alt="" uk-cover style="margin-top: 2rem;">
          </div>
        </div>
        <div class="uk-position-top uk-position-small uk-margin-small  uk-padding-small">
          <div class="uk-position-center">
            <ul class="uk-thumbnav">
              <li uk-slideshow-item="0"><a href="#"><img src="fig_imaging_1.png" width="100" height="67" alt=""></a></li>
              <li uk-slideshow-item="1"><a href="#"><img src="fig_imaging_2.png" width="100" height="67" alt=""></a></li>
              <li uk-slideshow-item="2"><a href="#"><img src="fig_imaging_3.png" width="100" height="67" alt=""></a></li>
            </ul>
          </div>
          
        </div>
      </div>
      <p>The robotic platform is designed for high maneuverability, 
      featuring an omnidirectional wheel system that enables full 360-degree movement. 
      Additionally, the system is powered by a high-capacity battery, 
      allowing for continuous operation for up to six hours, making it suitable 
      for extended field deployments in data acquisitions.</p>

  - title: Pixel-aligned RGB-NIR Dataset
  - text: |
      ### Drag bar in the middle to compare RGB and NIR images
  - overlay:
      {
        'back': { 'type': 'video', 'url': 'dataset_indoor_2_rgb.mp4' },
        'front': { 'type': 'video', 'url': 'dataset_indoor_2_nir.mp4' },
      }
  - overlay:
      {
        'back': { 'type': 'video', 'url': 'dataset_outdoor_1_rgb.mp4' },
        'front': { 'type': 'video', 'url': 'dataset_outdoor_1_nir.mp4' },
      }
  - text: |
      ## Data Acquisition

      Using our system, we collected a dataset comprising:

      - **Training Data**: 80 videos totaling **90,000 frames** under various lighting conditions.
      - **Testing Data**: 40 videos with **7,000 frames**.

      For each frame, we provide:

      - **Pixel-aligned RGB-NIR stereo images**
      - **Sparse LiDAR point clouds**
      - **Sensor timestamps**

      Public access to the dataset is available on [huggingface](https://huggingface.co/datasets/DivisonOfficer/Pixel-aligned_RGB-NIR_stereo_dataset).


      ## Dataset Composition

      We categorize our dataset based on **lighting conditions**:

  - text: |
      <div class="uk-child-width-1-2 uk-child-width-1-4@m" uk-grid>
        <div><div>
          <video
              src="data_thumb_0.mp4"
              loop
              muted
              uk-video="autoplay:inview"
              /></div>
          <span class="uk-text-meta">Night outdoor</figcaption>
        </div>
        <div><div>
          <video
              src="data_thumb_1.mp4"
              loop
              muted
              uk-video="autoplay:inview"
              /></div>
          <span class="uk-text-meta">Underground Parking Lot</figcaption>
        </div>
        <div><div>
          <video
              src="data_thumb_2.mp4"
              loop
              muted
              uk-video="autoplay:inview"
              /></div>
          <span class="uk-text-meta">Day Outdoor</figcaption>
        </div>
        <div><div>
          <video
              src="data_thumb_3.mp4"
              loop
              muted
              uk-video="autoplay:inview"
              /></div>
          <span class="uk-text-meta">Night Walkthrough</figcaption>
        </div>
        <div><div>
          <video
              src="data_thumb_4.mp4"
              loop
              muted
              uk-video="autoplay:inview"
              /></div>
          <span class="uk-text-meta">Night Square</figcaption>
        </div>
        <div><div>
          <video
              src="data_thumb_5.mp4"
              loop
              muted
              uk-video="autoplay:inview"
              /></div>
          <span class="uk-text-meta">Indoor Cafeteria</figcaption>
        </div>
        <div><div>
          <video
              src="data_thumb_6.mp4"
              loop
              muted
              uk-video="autoplay:inview"
              /></div>
          <span class="uk-text-meta">Indoor Hall</figcaption>
        </div>
        <div>
          <div>
          <video
              src="data_thumb_7.mp4"
              loop
              muted
              uk-video="autoplay:inview"
              />
              </div>
          <span class="uk-text-meta">Unstructured Objects</figcaption>
        </div>
      </div>

  - title: RGB-NIR Image Fusion
    text: |
      <div>
        <video
          src="v_method_1.mp4"
          loop
          muted
          uk-video="autoplay:inview"
          />
      </div>
      <p>
        We propose a novel RGB-NIR image fusion method for 3 channel vision tasks.
        This fusion method eccelarates the performance of the pretrained vision models such as stereo depth, semantic segmentation, and object detection.
          
      </p>

  - title: RGB-NIR Feature Fusion for Stereo Depth Estimation
    text: |
      <div>
        <video
          src="v_method_2.mp4"
          loop
          muted
          uk-video="autoplay:inview"
          />
      </div>
      <p>
        We estimate a series of disparity maps using the GRU structure of the RAFT-Stereo network. 
        We alternate between the fused and NIR correlation volumes, as input to the GRU at each iteration.
        Our scenario reflect RGB with active illumination, which intends use NIR mainly to restore stereo depth and RGB compensates NIR images
      </p>
  - title: Depth Estimation Results
    text: |
      <div uk-slider>
        <div class="uk-slider-items uk-child-width-1-1 uk-child-width-1-1@m uk-grid">
          <div>
            <video
              src="stereo_depth_1.mp4"
              loop
              muted
              uk-video="autoplay:inview"
              />
          </div>
          <div>
            <video
              src="stereo_depth_2.mp4"
              loop
              muted
              uk-video="autoplay:inview"
              />
          </div>
          <div>
            <video
              src="stereo_depth_3.mp4"
              loop
              muted
              uk-video="autoplay:inview"
              />
          </div>
          
        </div>
        <div class="uk-flex uk-flex-center uk-margin-small">
          <a class="uk-icon-button" href uk-slidenav-previous uk-slider-item="previous"></a>
          <a class="uk-icon-button uk-margin-small-left" href uk-slidenav-next uk-slider-item="next"></a>
        </div>
      </div>

  # - title: Media examples22s
  #   text: |
  #     Files in `public/` can be referenced directly: `<img src="001.jpg" />`
  #     <div class="uk-container uk-container-expand">
  #       <div class="uk-cover-container">
  #         <div
  #           id="container"
  #           style="position: relative; width: 800px; height: 450px; overflow: hidden;"
  #           class="uk-margin uk-padding"
  #         >
  #           <img src="001.jpg" alt="" uk-cover>
  #           <img src="001.jpg" alt="" uk-cover>
  #           <div
  #             id="splitBar"
  #             style="position: absolute; top: 0; left: 50%; width: 5px; height: 100%; cursor: ew-resize; background-color: rgba(255,255,255,0.5);"
  #           >
  #           </div>
  #         </div>
  #         <canvas width="600" height="400"></canvas>
  #       </div>
  #     </div>
  #     <div class="uk-position-relative" uk-slideshow="animation: fade">
  #       <div class="uk-slideshow-items">
  #         <div>
  #           <img src="001.jpg" alt="" uk-cover>
  #         </div>
  #         <div>
  #           <video
  #             src="MicrosoftTeams-video.mp4"
  #             loop
  #             muted
  #             uk-video="autoplay:inview"
  #             />
  #         </div>
  #         <div>
  #           <img src="003.jpg" alt="" uk-cover>
  #         </div>
  #       </div>
  #       <div class="uk-position-bottom-center uk-position-small">
  #         <ul class="uk-thumbnav">
  #           <li uk-slideshow-item="0"><a href="#"><img src="001.jpg" width="100" height="67" alt=""></a></li>
  #           <li uk-slideshow-item="1"><a href="#"><img src="002.jpg" width="100" height="67" alt=""></a></li>
  #           <li uk-slideshow-item="2"><a href="#"><img src="003.jpg" width="100" height="67" alt=""></a></li>
  #         </ul>
  #       </div>
  #     </div>

  #     Refer to [UIKit Video Components Documentation](https://getuikit.com/docs/video) and [Grid system](https://getuikit.com/docs/grid)
  #     <div class="uk-child-width-1-2 uk-child-width-1-3@m" uk-grid>
  #       <div>
  #         <img src="001.jpg">
  #         <span class="uk-text-meta">Fig1 - caption example</figcaption>
  #       </div>
  #       <div>
  #         <img src="002.jpg">
  #         <span class="uk-text-meta">Fig2 - caption example</figcaption>
  #       </div>
  #       <div>
  #         <img src="003.jpg">
  #         <span class="uk-text-meta">Fig3 - caption example</figcaption>
  #       </div>
  #     </div>

  #     [Slider](https://getuikit.com/docs/slider) component example
  #     <div uk-slider>
  #       <div class="uk-slider-items uk-child-width-1-1 uk-child-width-1-2@m uk-grid">
  #         <div>
  #           <video
  #             src="https://yootheme.com/site/images/media/yootheme-pro.mp4"
  #             loop
  #             muted
  #             uk-video="autoplay:inview"
  #             />
  #         </div>
  #         <div>
  #           <video
  #             src="https://yootheme.com/site/images/media/yootheme-pro.mp4"
  #             loop
  #             muted
  #             uk-video="autoplay:inview"
  #             />
  #         </div>
  #         <div>
  #           <video
  #             src="https://yootheme.com/site/images/media/yootheme-pro.mp4"
  #             loop
  #             muted
  #             uk-video="autoplay:inview"
  #             />
  #         </div>
  #       </div>
  #       <div class="uk-flex uk-flex-center uk-margin-small">
  #         <a class="uk-icon-button" href uk-slidenav-previous uk-slider-item="previous"></a>
  #         <a class="uk-icon-button uk-margin-small-left" href uk-slidenav-next uk-slider-item="next"></a>
  #       </div>
  #     </div>

  # - title: Markdown examples
  #   text: |
  #     Here's our demo text showcasing the power of markdown and KaTeX integration!
  #     Markdown allows you to easily format text using simple syntax.
  #     - **bold**
  #     - *italic*
  #     - `inline code`.

  #     You can also create headings of various levels:
  #     # Heading Level 1
  #     ## Heading Level 2
  #     ### Heading Level 3
  #     #### Heading Level 4
  #     Markdown allows you to create tables like the following:
  #     ### Fictitious AI Benchmark Results
  #     | Model Name          | Accuracy (%) | Inference Time (ms) |
  #     |---------------------|--------------|---------------------|
  #     | TransGPT-XT         | 96.3         | $\infty$                 |
  #     | GigaBERT Prime      | 94.7         | 9.5                 |
  #     | MegaLSTM-Pro        | 92.5         | 10.1                |
  #     | UltraTransformer    | 97.1         | 7.8                 |
  #     | **QuantumDNN-ALPHA**    | 95.8         | 8.5             |

  #     Of course, you can also directly write tables in HTML if needed. For more details, refer to the [UIKit Table documentation](https://getuikit.com/docs/table).

  #     <div class="uk-overflow-auto uk-width-1-1">
  #       <table class="uk-table uk-table-small uk-text-small uk-table-divider">
  #         <thead>
  #           <tr>
  #             <th>Model Name</th>
  #             <th>Accuracy (%)</th>
  #             <th>Inference Time (ms)</th>
  #             <th>Memory Usage (MB)</th>
  #             <th>Training Time (hours)</th>
  #           </tr>
  #         </thead>
  #         <tbody>
  #           <tr>
  #             <td>TransGPT-XT<br/>GigaBERT Prime</td>
  #             <td>96.3<br/>94.7</td>
  #             <td>8.2<br/>9.5</td>
  #             <td>1200<br/>1100</td>
  #             <td>36<br/>48</td>
  #           </tr>
  #           <tr>
  #             <td>MegaLSTM-Pro<br/>UltraTransformer</td>
  #             <td>92.5<br/>97.1</td>
  #             <td>10.1<br/>7.8</td>
  #             <td>1050<br/>1300</td>
  #             <td>56<br/>42</td>
  #           </tr>
  #           <tr class="uk-active">
  #             <td>QuantumDNN-ALPHA</td>
  #             <td>95.8</td>
  #             <td>8.5</td>
  #             <td>1250</td>
  #             <td>50</td>
  #           </tr>
  #         </tbody>
  #       </table>
  #     </div>
  # - title: KaTeX examples
  #   text: >
  #     $\KaTeX$ enables you to write mathematical expressions beautifully within your text (e.g. $\alpha$, $\beta$, $\gamma$ ).
  #     $$ax^2 + bx + c = 0$$
  #     $$ \int \oint \sum \prod $$
  #     $$ \begin{CD} A @>a>> B \\ @VbVV @AAcA \\ C @= D \end{CD} $$
  #     [KaTeX supports a wide range of mathematical symbols and equations](https://katex.org/docs/support_table.html), ensuring your technical content is both clear and visually appealing.
  #     With markdown for text formatting and KaTeX for mathematical expressions, our template empowers you to communicate complex ideas effectively. Whether you're writing a scientific paper or a technical blog post, harnessing these tools will elevate your content and engage your readers.
  # - title: Color Palette
  #   text: |
  #     To customize the theme, edit UIkit variables in [theme.scss](https://github.com/denkiwakame/academic-project-template/blob/project-page/src/scss/theme.scss). Material Design colors are available as variables (e.g. `$clr-blue-50` ). For the full set of colors, please visit [Material Design Color System](https://m2.material.io/design/color/the-color-system.html#tools-for-picking-colors).

  #     <div class="uk-overflow-auto">
  #     <table class="uk-table uk-table-small uk-text-small uk-table-divider">
  #       <thead>
  #         <tr>
  #           <th>50</th>
  #           <th>100</th>
  #           <th>200</th>
  #           <th>300</th>
  #           <th>400</th>
  #           <th>500</th>
  #         </tr>
  #       </thead>
  #       <tbody>
  #         <tr>
  #           <td bgcolor="#FFEBEE">$clr-red-50</td>
  #           <td bgcolor="#FFCCD2">$clr-red-100</td>
  #           <td bgcolor="#EF9A9A">$clr-red-200</td>
  #           <td bgcolor="#E57373">$clr-red-300</td>
  #           <td bgcolor="#FF5350">$clr-red-400</td>
  #           <td bgcolor="#F44336">$clr-red-500</td>
  #         </tr>
  #         <tr>
  #           <td bgcolor="#FCE4EC">$clr-pink-50</td>
  #           <td bgcolor="#F8BBD0">$clr-pink-100</td>
  #           <td bgcolor="#F48FB1">$clr-pink-200</td>
  #           <td bgcolor="#F06292">$clr-pink-300</td>
  #           <td bgcolor="#EC407A">$clr-pink-400</td>
  #           <td bgcolor="#E91E63">$clr-pink-500</td>
  #         </tr>
  #         <tr>
  #           <td bgcolor="#E8EAF6">$clr-indigo-50</td>
  #           <td bgcolor="#C5CAE9">$clr-indigo-100</td>
  #           <td bgcolor="#9FA8DA">$clr-indigo-200</td>
  #           <td bgcolor="#7986CB">$clr-indigo-300</td>
  #           <td bgcolor="#5C6BC0">$clr-indigo-400</td>
  #           <td bgcolor="#3F51B5">$clr-indigo-500</td>
  #         </tr>
  #         <tr>
  #           <td bgcolor="#E0F7FA">$clr-cyan-50</td>
  #           <td bgcolor="#B2EBF2">$clr-cyan-100</td>
  #           <td bgcolor="#80DEEA">$clr-cyan-200</td>
  #           <td bgcolor="#4DD0E1">$clr-cyan-300</td>
  #           <td bgcolor="#26C6DA">$clr-cyan-400</td>
  #           <td bgcolor="#00BCD4">$clr-cyan-500</td>
  #         </tr>
  #         <tr>
  #           <td bgcolor="#E0F2F1">$clr-teal-50</td>
  #           <td bgcolor="#B2DFDB">$clr-teal-100</td>
  #           <td bgcolor="#80CBC4">$clr-teal-200</td>
  #           <td bgcolor="#4DB6AC">$clr-teal-300</td>
  #           <td bgcolor="#26A69A">$clr-teal-400</td>
  #           <td bgcolor="#009688">$clr-teal-500</td>
  #         </tr>
  #         <tr>
  #           <td bgcolor="#FFF8E1">$clr-amber-50</td>
  #           <td bgcolor="#FFECB3">$clr-amber-100</td>
  #           <td bgcolor="#FFE082">$clr-amber-200</td>
  #           <td bgcolor="#FFD54F">$clr-amber-300</td>
  #           <td bgcolor="#FFCA28">$clr-amber-400</td>
  #           <td bgcolor="#FFC107">$clr-amber-500</td>
  #         </tr>
  #         <tr>
  #           <td bgcolor="#F9FBE7">$clr-lime-50</td>
  #           <td bgcolor="#F0F4C3">$clr-lime-100</td>
  #           <td bgcolor="#E6EE9C">$clr-lime-200</td>
  #           <td bgcolor="#DCE775">$clr-lime-300</td>
  #           <td bgcolor="#D4E157">$clr-lime-400</td>
  #           <td bgcolor="#CDDC39">$clr-lime-500</td>
  #         </tr>
  #         <tr>
  #           <td bgcolor="#FAFAFA">$clr-grey-50</td>
  #           <td bgcolor="#F5F5F5">$clr-grey-100</td>
  #           <td bgcolor="#EEEEEE">$clr-grey-200</td>
  #           <td bgcolor="#E0E0E0">$clr-grey-300</td>
  #           <td bgcolor="#BDBDBD">$clr-grey-400</td>
  #           <td bgcolor="#9E9E9E">$clr-grey-500</td>
  #         </tr>
  #       </tbody>
  #     </table>
  #     </div>
projects: # relevant projects
  - title: Dual Exposure Stereo for Extended Dynamic Range 3D Imaging
    description: Juhyung Choi, Jinnyeong Kim, Seokjun Choi, Jinwoo Lee, Samuel Brucker, Mario Bijelic, Felix Heide, Seung-Hwan Baek
    img: https://lh3.googleusercontent.com/huyJyvZkEUocLLj2VsMC85HN3cPmvTSbsoEc1oDVS1W8_2DIKmNkNHZzQPEokrU4pHW7tY7RZTxCL7IFUSsVsa1TbXMw_GXN3zLjdRsj2r70WjjqdEBPPz-eDgBlnZoJhQ=w1280
    journal: "CVPR'25"
    url: https://arxiv.org/abs/2412.02351
  # - title: Relevant Project II
  #   description: abstract text
  #   img: 001.jpg
  #   journal: "EFGH'22"
  #   url: https://denkiwakame.github.io/academic-project-template/
  # - title: Relevant Project III
  #   description: abstract text
  #   img: 002.jpg
  #   journal: "IJKL'22"
  #   url: https://denkiwakame.github.io/academic-project-template/
